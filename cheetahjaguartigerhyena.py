# -*- coding: utf-8 -*-
"""CheetahJaguarTigerHyena.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B45FqFekEkGACXvSlfaxr3koaJK05YEx
"""

import tensorflow as tf
from IPython.display import Image, display

import matplotlib.pyplot as plt
import tensorflow_hub as hub

import numpy as np
import zipfile
import warnings
warnings.filterwarnings('ignore')

!nvidia-smi

cd /content/

ls /content/drive/MyDrive/Datasets/cheetah_zip

local_zip = '/content/drive/MyDrive/Datasets/cheetah_zip/tiger_validation_resized.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp/animalds/val/tiger')
zip_ref.close()

batch_size = 64
img_height = 224
img_width = 224

train_ds = tf.keras.preprocessing.image_dataset_from_directory('/tmp/animalds/train',
  seed=111,
  image_size=(img_height, img_width),
  batch_size=batch_size)

val_ds = tf.keras.preprocessing.image_dataset_from_directory('/tmp/animalds/val',
  seed=111,
  image_size=(img_height, img_width),
  batch_size=batch_size)

classes=train_ds.class_names
print(classes)

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(classes[labels[i]])
    plt.axis("off")

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

feature_extractor = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"

feature_extractor_layer = hub.KerasLayer(feature_extractor, input_shape=(img_height,img_width,3)) 

feature_extractor_layer.trainable = False

normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)

model = tf.keras.Sequential([
  normalization_layer,
  feature_extractor_layer,
  tf.keras.layers.Dropout(0.3),
  tf.keras.layers.Dense(4,activation='softmax')
])

model.compile(
  optimizer='adam',
  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics=['accuracy'])

history = model.fit(train_ds, epochs=20, validation_data=val_ds)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train_loss', 'val_loss'], loc='best')
plt.show()

plt.figure(figsize=(10, 10))
for images, labels in val_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)

    plt.tight_layout()
    
    img = tf.keras.preprocessing.image.img_to_array(images[i])                    
    img = np.expand_dims(img, axis=0)  

    pred=model.predict(img)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title("Actual Label: %s" % classes[labels[i]])
    plt.text(1, 240, "Predicted Label: %s" % classes[np.argmax(pred)], fontsize=12)

    plt.axis("off")

model.save('./models', save_format='tf')

!ls -alrt models

model_loaded = tf.keras.models.load_model('./models/')
model_loaded.summary()

from PIL import Image
import numpy as np
from skimage import transform
def process(filename):
   np_image = Image.open(filename)
   np_image = np.array(np_image).astype('float32')
   np_image = transform.resize(np_image, (224, 224, 3))
   np_image = np.expand_dims(np_image, axis=0)
   return np_image

pred_label=model_loaded.predict(process('/tmp/animalds/val/hyena/hyena_000_val_resized.jpg'))
print(classes[np.argmax(pred_label)])

pred_label

!zip -r models.zip models/

